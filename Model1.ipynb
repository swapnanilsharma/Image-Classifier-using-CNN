{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training from scratch: \n",
    "As we have only few training dataset(1000 images for each class), the accuracy we observed is very less(Training accuracy: 81.8% Testing accuracy: 79%) with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.7179 - acc: 0.5190 - val_loss: 0.7549 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.6777 - acc: 0.5865 - val_loss: 0.6167 - val_acc: 0.6587\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6503 - acc: 0.6375 - val_loss: 0.6213 - val_acc: 0.6550\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6314 - acc: 0.6580 - val_loss: 0.5815 - val_acc: 0.6875\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.6032 - acc: 0.6690 - val_loss: 0.9528 - val_acc: 0.5300\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5849 - acc: 0.6980 - val_loss: 0.5747 - val_acc: 0.6975\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.5717 - acc: 0.7015 - val_loss: 0.5828 - val_acc: 0.6887\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.5660 - acc: 0.7115 - val_loss: 0.5701 - val_acc: 0.6900\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5517 - acc: 0.7260 - val_loss: 0.5347 - val_acc: 0.7125\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5357 - acc: 0.7475 - val_loss: 0.6040 - val_acc: 0.7037\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5312 - acc: 0.7520 - val_loss: 0.5664 - val_acc: 0.7212\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5212 - acc: 0.7510 - val_loss: 0.5148 - val_acc: 0.7338\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.5215 - acc: 0.7540 - val_loss: 0.6028 - val_acc: 0.6900\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5026 - acc: 0.7615 - val_loss: 0.5568 - val_acc: 0.7150\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5030 - acc: 0.7715 - val_loss: 0.5299 - val_acc: 0.7450\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4906 - acc: 0.7705 - val_loss: 0.5486 - val_acc: 0.7325\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4703 - acc: 0.7730 - val_loss: 0.5112 - val_acc: 0.7750\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4759 - acc: 0.7670 - val_loss: 0.4895 - val_acc: 0.7700\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4768 - acc: 0.7925 - val_loss: 0.5049 - val_acc: 0.7688\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4763 - acc: 0.7830 - val_loss: 0.5440 - val_acc: 0.7488\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4939 - acc: 0.7920 - val_loss: 0.5459 - val_acc: 0.7538\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.4759 - acc: 0.7925 - val_loss: 0.5313 - val_acc: 0.7388\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4682 - acc: 0.7965 - val_loss: 0.4780 - val_acc: 0.7775\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4556 - acc: 0.8015 - val_loss: 0.5504 - val_acc: 0.7500\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4384 - acc: 0.8055 - val_loss: 0.5327 - val_acc: 0.7725\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.4760 - acc: 0.7870 - val_loss: 0.5160 - val_acc: 0.7725\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4329 - acc: 0.8035 - val_loss: 0.4825 - val_acc: 0.7875\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4568 - acc: 0.7980 - val_loss: 0.5161 - val_acc: 0.7725\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4705 - acc: 0.8040 - val_loss: 0.5214 - val_acc: 0.7788\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4508 - acc: 0.8040 - val_loss: 0.5162 - val_acc: 0.7750\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4483 - acc: 0.7980 - val_loss: 0.5874 - val_acc: 0.7600\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4421 - acc: 0.8165 - val_loss: 0.5267 - val_acc: 0.7462\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.4543 - acc: 0.8105 - val_loss: 0.5293 - val_acc: 0.8013\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.4382 - acc: 0.8170 - val_loss: 0.4919 - val_acc: 0.8025\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4348 - acc: 0.8115 - val_loss: 0.6256 - val_acc: 0.7700\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4355 - acc: 0.8125 - val_loss: 0.5310 - val_acc: 0.8150\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4552 - acc: 0.8020 - val_loss: 0.5436 - val_acc: 0.7937\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4521 - acc: 0.8090 - val_loss: 0.4937 - val_acc: 0.7800\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4166 - acc: 0.8160 - val_loss: 0.8920 - val_acc: 0.7362\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4471 - acc: 0.8080 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4210 - acc: 0.8180 - val_loss: 0.7819 - val_acc: 0.7550\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4442 - acc: 0.8175 - val_loss: 0.5815 - val_acc: 0.8037\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4154 - acc: 0.8275 - val_loss: 0.5090 - val_acc: 0.7875\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4385 - acc: 0.8140 - val_loss: 0.5149 - val_acc: 0.7662\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4608 - acc: 0.7970 - val_loss: 0.4940 - val_acc: 0.7850\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4405 - acc: 0.8130 - val_loss: 0.6949 - val_acc: 0.7950\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4387 - acc: 0.8190 - val_loss: 0.5213 - val_acc: 0.7650\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4459 - acc: 0.8200 - val_loss: 0.6330 - val_acc: 0.7550\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4240 - acc: 0.8185 - val_loss: 0.4968 - val_acc: 0.7750\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4143 - acc: 0.8180 - val_loss: 0.4919 - val_acc: 0.7900\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using the bottleneck features of a pre-trained network\n",
    "Here we are using VGG16 models conv layers without fully connected layers. We train our model only on newly adeded fully connected layer. It improves the accuracy drastically. Training accuracy: 99.65% Testing accuracy: 89.38% with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 2s 797us/step - loss: 0.7193 - acc: 0.7510 - val_loss: 0.2727 - val_acc: 0.8912\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.3724 - acc: 0.8555 - val_loss: 0.2480 - val_acc: 0.8900\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.3116 - acc: 0.8800 - val_loss: 0.2302 - val_acc: 0.9075\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.2807 - acc: 0.8920 - val_loss: 0.8308 - val_acc: 0.7300\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.2371 - acc: 0.9100 - val_loss: 0.3093 - val_acc: 0.9062\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.2236 - acc: 0.9155 - val_loss: 0.4095 - val_acc: 0.8712\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.1963 - acc: 0.9365 - val_loss: 0.3916 - val_acc: 0.8738\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.1493 - acc: 0.9365 - val_loss: 0.3305 - val_acc: 0.9050\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.1533 - acc: 0.9380 - val_loss: 0.3729 - val_acc: 0.8912\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.1280 - acc: 0.9555 - val_loss: 0.3542 - val_acc: 0.9012\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.1061 - acc: 0.9545 - val_loss: 0.3912 - val_acc: 0.9025\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.1126 - acc: 0.9535 - val_loss: 0.3707 - val_acc: 0.9012\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0951 - acc: 0.9615 - val_loss: 0.4436 - val_acc: 0.8988\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0851 - acc: 0.9710 - val_loss: 0.4802 - val_acc: 0.9038\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0603 - acc: 0.9765 - val_loss: 0.6427 - val_acc: 0.8825\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0674 - acc: 0.9765 - val_loss: 0.5680 - val_acc: 0.8862\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0545 - acc: 0.9795 - val_loss: 0.6387 - val_acc: 0.8838\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.6285 - val_acc: 0.9025\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0430 - acc: 0.9880 - val_loss: 0.6726 - val_acc: 0.8988\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0509 - acc: 0.9820 - val_loss: 0.6045 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0535 - acc: 0.9845 - val_loss: 0.5799 - val_acc: 0.8925\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 441us/step - loss: 0.0497 - acc: 0.9825 - val_loss: 0.8237 - val_acc: 0.8850\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.6409 - val_acc: 0.9025\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0348 - acc: 0.9865 - val_loss: 0.8484 - val_acc: 0.8725\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.9899 - val_acc: 0.8825\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.6967 - val_acc: 0.8950\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0378 - acc: 0.9900 - val_loss: 0.7732 - val_acc: 0.9038\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.0444 - acc: 0.9880 - val_loss: 0.7412 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0275 - acc: 0.9880 - val_loss: 0.8248 - val_acc: 0.8925\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.8190 - val_acc: 0.9087\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0400 - acc: 0.9885 - val_loss: 0.7442 - val_acc: 0.8925\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0350 - acc: 0.9900 - val_loss: 0.8898 - val_acc: 0.8900\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.8249 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0216 - acc: 0.9920 - val_loss: 0.8324 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.8888\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0250 - acc: 0.9930 - val_loss: 1.0133 - val_acc: 0.8775\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 1.1741 - val_acc: 0.8662\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.8952 - val_acc: 0.8975\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.8963 - val_acc: 0.8850\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.8874 - val_acc: 0.8912\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.8790 - val_acc: 0.9025\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.9012\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.9398 - val_acc: 0.8950\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0057 - acc: 0.9975 - val_loss: 1.2706 - val_acc: 0.8712\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0280 - acc: 0.9930 - val_loss: 1.0187 - val_acc: 0.8962\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.0276 - acc: 0.9920 - val_loss: 0.9128 - val_acc: 0.8950\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.9995 - val_acc: 0.8900\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.9677 - val_acc: 0.8938\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 1.0332 - val_acc: 0.8862\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', \"rb\", buffering=0))\n",
    "    train_labels = np.array(\n",
    "        [0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', \"rb\", buffering=0))\n",
    "    validation_labels = np.array(\n",
    "        [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-tuning the top layers of a a pre-trained network\n",
    "To further improve our previous result, we can try to \"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier. Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates. In our case, this can be done in 3 steps:\n",
    "\n",
    "-instantiate the convolutional base of VGG16 and load its weights\n",
    "-add our previously defined fully-connected model on top, and load its weights\n",
    "-freeze the layers of the VGG16 model up to the last convolutional block\n",
    "\n",
    "Training accuracy: 93.80% Testing accuracy: 89.38% with 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=5, validation_data=<keras.pre..., steps_per_epoch=125, validation_steps=800)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.5378 - acc: 0.9355 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.5641 - acc: 0.9330 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 88s 706ms/step - loss: 0.5025 - acc: 0.9360 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 88s 701ms/step - loss: 0.5565 - acc: 0.9310 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 88s 707ms/step - loss: 0.4724 - acc: 0.9380 - val_loss: 0.9566 - val_acc: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176838cf198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# build the VGG16 network\n",
    "#input_tensor1 = Input(shape=(img_width,img_height,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#model.add(top_model)\n",
    "model = Model(inputs= model.input, outputs= top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_fine_tune_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 0\n",
      "Non-trainable params: 16,812,353\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,097,665\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a new image class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\keras\\models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Dog\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('final_fine_tune_weight.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread('test1.jpg')\n",
    "img = cv2.resize(img,(150,150))\n",
    "img = np.reshape(img,[1,150,150,3])\n",
    "\n",
    "classes = model.predict(img)\n",
    "\n",
    "def print_class(classes):\n",
    "    if classes[0][0]==0.0:\n",
    "        print(\"It is a Cat\")\n",
    "    elif classes[0][0]==1.0:\n",
    "        print(\"It is a Dog\")\n",
    "\n",
    "print_class(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
