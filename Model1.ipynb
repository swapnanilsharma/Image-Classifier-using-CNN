{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training from scratch: \n",
    "As we have only few training dataset(1000 images for each class), the accuracy we observed is very less(Training accuracy: 81.8% Testing accuracy: 79%) with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.7179 - acc: 0.5190 - val_loss: 0.7549 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.6777 - acc: 0.5865 - val_loss: 0.6167 - val_acc: 0.6587\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6503 - acc: 0.6375 - val_loss: 0.6213 - val_acc: 0.6550\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6314 - acc: 0.6580 - val_loss: 0.5815 - val_acc: 0.6875\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.6032 - acc: 0.6690 - val_loss: 0.9528 - val_acc: 0.5300\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5849 - acc: 0.6980 - val_loss: 0.5747 - val_acc: 0.6975\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.5717 - acc: 0.7015 - val_loss: 0.5828 - val_acc: 0.6887\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.5660 - acc: 0.7115 - val_loss: 0.5701 - val_acc: 0.6900\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5517 - acc: 0.7260 - val_loss: 0.5347 - val_acc: 0.7125\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5357 - acc: 0.7475 - val_loss: 0.6040 - val_acc: 0.7037\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5312 - acc: 0.7520 - val_loss: 0.5664 - val_acc: 0.7212\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5212 - acc: 0.7510 - val_loss: 0.5148 - val_acc: 0.7338\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.5215 - acc: 0.7540 - val_loss: 0.6028 - val_acc: 0.6900\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5026 - acc: 0.7615 - val_loss: 0.5568 - val_acc: 0.7150\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5030 - acc: 0.7715 - val_loss: 0.5299 - val_acc: 0.7450\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4906 - acc: 0.7705 - val_loss: 0.5486 - val_acc: 0.7325\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4703 - acc: 0.7730 - val_loss: 0.5112 - val_acc: 0.7750\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4759 - acc: 0.7670 - val_loss: 0.4895 - val_acc: 0.7700\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4768 - acc: 0.7925 - val_loss: 0.5049 - val_acc: 0.7688\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4763 - acc: 0.7830 - val_loss: 0.5440 - val_acc: 0.7488\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4939 - acc: 0.7920 - val_loss: 0.5459 - val_acc: 0.7538\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.4759 - acc: 0.7925 - val_loss: 0.5313 - val_acc: 0.7388\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4682 - acc: 0.7965 - val_loss: 0.4780 - val_acc: 0.7775\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4556 - acc: 0.8015 - val_loss: 0.5504 - val_acc: 0.7500\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4384 - acc: 0.8055 - val_loss: 0.5327 - val_acc: 0.7725\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.4760 - acc: 0.7870 - val_loss: 0.5160 - val_acc: 0.7725\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4329 - acc: 0.8035 - val_loss: 0.4825 - val_acc: 0.7875\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4568 - acc: 0.7980 - val_loss: 0.5161 - val_acc: 0.7725\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4705 - acc: 0.8040 - val_loss: 0.5214 - val_acc: 0.7788\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4508 - acc: 0.8040 - val_loss: 0.5162 - val_acc: 0.7750\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4483 - acc: 0.7980 - val_loss: 0.5874 - val_acc: 0.7600\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4421 - acc: 0.8165 - val_loss: 0.5267 - val_acc: 0.7462\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.4543 - acc: 0.8105 - val_loss: 0.5293 - val_acc: 0.8013\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.4382 - acc: 0.8170 - val_loss: 0.4919 - val_acc: 0.8025\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4348 - acc: 0.8115 - val_loss: 0.6256 - val_acc: 0.7700\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4355 - acc: 0.8125 - val_loss: 0.5310 - val_acc: 0.8150\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4552 - acc: 0.8020 - val_loss: 0.5436 - val_acc: 0.7937\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4521 - acc: 0.8090 - val_loss: 0.4937 - val_acc: 0.7800\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4166 - acc: 0.8160 - val_loss: 0.8920 - val_acc: 0.7362\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4471 - acc: 0.8080 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4210 - acc: 0.8180 - val_loss: 0.7819 - val_acc: 0.7550\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4442 - acc: 0.8175 - val_loss: 0.5815 - val_acc: 0.8037\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4154 - acc: 0.8275 - val_loss: 0.5090 - val_acc: 0.7875\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4385 - acc: 0.8140 - val_loss: 0.5149 - val_acc: 0.7662\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4608 - acc: 0.7970 - val_loss: 0.4940 - val_acc: 0.7850\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4405 - acc: 0.8130 - val_loss: 0.6949 - val_acc: 0.7950\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4387 - acc: 0.8190 - val_loss: 0.5213 - val_acc: 0.7650\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4459 - acc: 0.8200 - val_loss: 0.6330 - val_acc: 0.7550\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4240 - acc: 0.8185 - val_loss: 0.4968 - val_acc: 0.7750\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4143 - acc: 0.8180 - val_loss: 0.4919 - val_acc: 0.7900\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using the bottleneck features of a pre-trained network\n",
    "Here we are using VGG16 models conv layers without fully connected layers. We train our model only on newly adeded fully connected layer. It improves the accuracy drastically. Training accuracy: 99.65% Testing accuracy: 89.38% with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 2s 797us/step - loss: 0.7193 - acc: 0.7510 - val_loss: 0.2727 - val_acc: 0.8912\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.3724 - acc: 0.8555 - val_loss: 0.2480 - val_acc: 0.8900\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.3116 - acc: 0.8800 - val_loss: 0.2302 - val_acc: 0.9075\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.2807 - acc: 0.8920 - val_loss: 0.8308 - val_acc: 0.7300\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.2371 - acc: 0.9100 - val_loss: 0.3093 - val_acc: 0.9062\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.2236 - acc: 0.9155 - val_loss: 0.4095 - val_acc: 0.8712\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.1963 - acc: 0.9365 - val_loss: 0.3916 - val_acc: 0.8738\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.1493 - acc: 0.9365 - val_loss: 0.3305 - val_acc: 0.9050\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.1533 - acc: 0.9380 - val_loss: 0.3729 - val_acc: 0.8912\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.1280 - acc: 0.9555 - val_loss: 0.3542 - val_acc: 0.9012\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.1061 - acc: 0.9545 - val_loss: 0.3912 - val_acc: 0.9025\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.1126 - acc: 0.9535 - val_loss: 0.3707 - val_acc: 0.9012\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0951 - acc: 0.9615 - val_loss: 0.4436 - val_acc: 0.8988\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0851 - acc: 0.9710 - val_loss: 0.4802 - val_acc: 0.9038\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0603 - acc: 0.9765 - val_loss: 0.6427 - val_acc: 0.8825\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0674 - acc: 0.9765 - val_loss: 0.5680 - val_acc: 0.8862\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0545 - acc: 0.9795 - val_loss: 0.6387 - val_acc: 0.8838\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.6285 - val_acc: 0.9025\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0430 - acc: 0.9880 - val_loss: 0.6726 - val_acc: 0.8988\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0509 - acc: 0.9820 - val_loss: 0.6045 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0535 - acc: 0.9845 - val_loss: 0.5799 - val_acc: 0.8925\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 441us/step - loss: 0.0497 - acc: 0.9825 - val_loss: 0.8237 - val_acc: 0.8850\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.6409 - val_acc: 0.9025\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0348 - acc: 0.9865 - val_loss: 0.8484 - val_acc: 0.8725\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.9899 - val_acc: 0.8825\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.6967 - val_acc: 0.8950\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0378 - acc: 0.9900 - val_loss: 0.7732 - val_acc: 0.9038\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.0444 - acc: 0.9880 - val_loss: 0.7412 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0275 - acc: 0.9880 - val_loss: 0.8248 - val_acc: 0.8925\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.8190 - val_acc: 0.9087\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0400 - acc: 0.9885 - val_loss: 0.7442 - val_acc: 0.8925\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0350 - acc: 0.9900 - val_loss: 0.8898 - val_acc: 0.8900\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.8249 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0216 - acc: 0.9920 - val_loss: 0.8324 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.8888\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0250 - acc: 0.9930 - val_loss: 1.0133 - val_acc: 0.8775\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 1.1741 - val_acc: 0.8662\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.8952 - val_acc: 0.8975\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.8963 - val_acc: 0.8850\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.8874 - val_acc: 0.8912\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.8790 - val_acc: 0.9025\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.9012\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.9398 - val_acc: 0.8950\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0057 - acc: 0.9975 - val_loss: 1.2706 - val_acc: 0.8712\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0280 - acc: 0.9930 - val_loss: 1.0187 - val_acc: 0.8962\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.0276 - acc: 0.9920 - val_loss: 0.9128 - val_acc: 0.8950\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.9995 - val_acc: 0.8900\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.9677 - val_acc: 0.8938\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 1.0332 - val_acc: 0.8862\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', \"rb\", buffering=0))\n",
    "    train_labels = np.array(\n",
    "        [0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', \"rb\", buffering=0))\n",
    "    validation_labels = np.array(\n",
    "        [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-tuning the top layers of a a pre-trained network\n",
    "To further improve our previous result, we can try to \"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier. Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates. In our case, this can be done in 3 steps:\n",
    "\n",
    "-instantiate the convolutional base of VGG16 and load its weights\n",
    "-add our previously defined fully-connected model on top, and load its weights\n",
    "-freeze the layers of the VGG16 model up to the last convolutional block\n",
    "\n",
    "Training accuracy: 93.80% Testing accuracy: 89.38% with 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=5, validation_data=<keras.pre..., steps_per_epoch=125, validation_steps=800)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.5378 - acc: 0.9355 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.5641 - acc: 0.9330 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 88s 706ms/step - loss: 0.5025 - acc: 0.9360 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 88s 701ms/step - loss: 0.5565 - acc: 0.9310 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 88s 707ms/step - loss: 0.4724 - acc: 0.9380 - val_loss: 0.9566 - val_acc: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176838cf198>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# build the VGG16 network\n",
    "#input_tensor1 = Input(shape=(img_width,img_height,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#model.add(top_model)\n",
    "model = Model(inputs= model.input, outputs= top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_fine_tune_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 0\n",
      "Non-trainable params: 16,812,353\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,097,665\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_test, predict_y):\n",
    "    C = confusion_matrix(y_test, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "   \n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "   \n",
    "    labels = [0,1]   #[0,1,2,3,4,5,6,7,8,9]\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a new image class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swapnanil\\Anaconda3_New\\lib\\site-packages\\keras\\models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Cat\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('final_fine_tune_weight.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def print_class(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img,(150,150))\n",
    "    img = np.reshape(img,[1,150,150,3])\n",
    "    classes = model.predict(img)\n",
    "    if classes[0][0]==0.0:\n",
    "        print(\"It is a Cat\")\n",
    "    elif classes[0][0]==1.0:\n",
    "        print(\"It is a Dog\")\n",
    "\n",
    "def return_class(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img,(150,150))\n",
    "    img = np.reshape(img,[1,150,150,3])\n",
    "    classes = model.predict(img)\n",
    "    return int(classes[0][0])\n",
    "    \n",
    "\n",
    "print_class(\"test.jpg\")\n",
    "print(return_class(\"test1.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix for the fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Confusion matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176b5a495c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Precision matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176c0365748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of columns in precision matrix [1. 1.]\n",
      "-------------------------------------------------- Recall matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176c4075390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of rows in precision matrix [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_samples = 800\n",
    "validation_actual = np.array(\n",
    "        [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "validation_predicted = []\n",
    "j=k=0\n",
    "for i in range(int(nb_validation_samples / 2)):\n",
    "    j=1000+i\n",
    "    validation_predicted.append(return_class(\"data/validation/cats/cat.%s.jpg\" % j))\n",
    "\n",
    "for i in range(int(nb_validation_samples / 2)):\n",
    "    k=1000+i\n",
    "    validation_predicted.append(return_class(\"data/validation/dogs/dog.%s.jpg\" % k))\n",
    "validation_predicted = np.array(validation_predicted)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(validation_actual, validation_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
