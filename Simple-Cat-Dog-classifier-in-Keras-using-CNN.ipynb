{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training from scratch: \n",
    "As we have only few training dataset(1000 images for each class), the accuracy we observed is very less(Training accuracy: 81.8% Testing accuracy: 79%) with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.7179 - acc: 0.5190 - val_loss: 0.7549 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.6777 - acc: 0.5865 - val_loss: 0.6167 - val_acc: 0.6587\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6503 - acc: 0.6375 - val_loss: 0.6213 - val_acc: 0.6550\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6314 - acc: 0.6580 - val_loss: 0.5815 - val_acc: 0.6875\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.6032 - acc: 0.6690 - val_loss: 0.9528 - val_acc: 0.5300\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5849 - acc: 0.6980 - val_loss: 0.5747 - val_acc: 0.6975\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.5717 - acc: 0.7015 - val_loss: 0.5828 - val_acc: 0.6887\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.5660 - acc: 0.7115 - val_loss: 0.5701 - val_acc: 0.6900\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5517 - acc: 0.7260 - val_loss: 0.5347 - val_acc: 0.7125\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5357 - acc: 0.7475 - val_loss: 0.6040 - val_acc: 0.7037\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5312 - acc: 0.7520 - val_loss: 0.5664 - val_acc: 0.7212\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5212 - acc: 0.7510 - val_loss: 0.5148 - val_acc: 0.7338\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.5215 - acc: 0.7540 - val_loss: 0.6028 - val_acc: 0.6900\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5026 - acc: 0.7615 - val_loss: 0.5568 - val_acc: 0.7150\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5030 - acc: 0.7715 - val_loss: 0.5299 - val_acc: 0.7450\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4906 - acc: 0.7705 - val_loss: 0.5486 - val_acc: 0.7325\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4703 - acc: 0.7730 - val_loss: 0.5112 - val_acc: 0.7750\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4759 - acc: 0.7670 - val_loss: 0.4895 - val_acc: 0.7700\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4768 - acc: 0.7925 - val_loss: 0.5049 - val_acc: 0.7688\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4763 - acc: 0.7830 - val_loss: 0.5440 - val_acc: 0.7488\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.4939 - acc: 0.7920 - val_loss: 0.5459 - val_acc: 0.7538\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.4759 - acc: 0.7925 - val_loss: 0.5313 - val_acc: 0.7388\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4682 - acc: 0.7965 - val_loss: 0.4780 - val_acc: 0.7775\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4556 - acc: 0.8015 - val_loss: 0.5504 - val_acc: 0.7500\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4384 - acc: 0.8055 - val_loss: 0.5327 - val_acc: 0.7725\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.4760 - acc: 0.7870 - val_loss: 0.5160 - val_acc: 0.7725\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4329 - acc: 0.8035 - val_loss: 0.4825 - val_acc: 0.7875\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4568 - acc: 0.7980 - val_loss: 0.5161 - val_acc: 0.7725\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4705 - acc: 0.8040 - val_loss: 0.5214 - val_acc: 0.7788\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4508 - acc: 0.8040 - val_loss: 0.5162 - val_acc: 0.7750\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4483 - acc: 0.7980 - val_loss: 0.5874 - val_acc: 0.7600\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4421 - acc: 0.8165 - val_loss: 0.5267 - val_acc: 0.7462\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.4543 - acc: 0.8105 - val_loss: 0.5293 - val_acc: 0.8013\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.4382 - acc: 0.8170 - val_loss: 0.4919 - val_acc: 0.8025\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4348 - acc: 0.8115 - val_loss: 0.6256 - val_acc: 0.7700\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4355 - acc: 0.8125 - val_loss: 0.5310 - val_acc: 0.8150\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.4552 - acc: 0.8020 - val_loss: 0.5436 - val_acc: 0.7937\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4521 - acc: 0.8090 - val_loss: 0.4937 - val_acc: 0.7800\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4166 - acc: 0.8160 - val_loss: 0.8920 - val_acc: 0.7362\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4471 - acc: 0.8080 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.4210 - acc: 0.8180 - val_loss: 0.7819 - val_acc: 0.7550\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4442 - acc: 0.8175 - val_loss: 0.5815 - val_acc: 0.8037\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4154 - acc: 0.8275 - val_loss: 0.5090 - val_acc: 0.7875\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4385 - acc: 0.8140 - val_loss: 0.5149 - val_acc: 0.7662\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4608 - acc: 0.7970 - val_loss: 0.4940 - val_acc: 0.7850\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4405 - acc: 0.8130 - val_loss: 0.6949 - val_acc: 0.7950\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4387 - acc: 0.8190 - val_loss: 0.5213 - val_acc: 0.7650\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.4459 - acc: 0.8200 - val_loss: 0.6330 - val_acc: 0.7550\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.4240 - acc: 0.8185 - val_loss: 0.4968 - val_acc: 0.7750\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.4143 - acc: 0.8180 - val_loss: 0.4919 - val_acc: 0.7900\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using the bottleneck features of a pre-trained network\n",
    "Here we are using VGG16 models conv layers without fully connected layers. We train our model only on newly adeded fully connected layer. It improves the accuracy drastically. Training accuracy: 99.65% Testing accuracy: 89.38% with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 2s 797us/step - loss: 0.7193 - acc: 0.7510 - val_loss: 0.2727 - val_acc: 0.8912\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.3724 - acc: 0.8555 - val_loss: 0.2480 - val_acc: 0.8900\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.3116 - acc: 0.8800 - val_loss: 0.2302 - val_acc: 0.9075\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.2807 - acc: 0.8920 - val_loss: 0.8308 - val_acc: 0.7300\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.2371 - acc: 0.9100 - val_loss: 0.3093 - val_acc: 0.9062\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.2236 - acc: 0.9155 - val_loss: 0.4095 - val_acc: 0.8712\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.1963 - acc: 0.9365 - val_loss: 0.3916 - val_acc: 0.8738\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.1493 - acc: 0.9365 - val_loss: 0.3305 - val_acc: 0.9050\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.1533 - acc: 0.9380 - val_loss: 0.3729 - val_acc: 0.8912\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.1280 - acc: 0.9555 - val_loss: 0.3542 - val_acc: 0.9012\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.1061 - acc: 0.9545 - val_loss: 0.3912 - val_acc: 0.9025\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.1126 - acc: 0.9535 - val_loss: 0.3707 - val_acc: 0.9012\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0951 - acc: 0.9615 - val_loss: 0.4436 - val_acc: 0.8988\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0851 - acc: 0.9710 - val_loss: 0.4802 - val_acc: 0.9038\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0603 - acc: 0.9765 - val_loss: 0.6427 - val_acc: 0.8825\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0674 - acc: 0.9765 - val_loss: 0.5680 - val_acc: 0.8862\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0545 - acc: 0.9795 - val_loss: 0.6387 - val_acc: 0.8838\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.6285 - val_acc: 0.9025\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0430 - acc: 0.9880 - val_loss: 0.6726 - val_acc: 0.8988\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0509 - acc: 0.9820 - val_loss: 0.6045 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0535 - acc: 0.9845 - val_loss: 0.5799 - val_acc: 0.8925\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 441us/step - loss: 0.0497 - acc: 0.9825 - val_loss: 0.8237 - val_acc: 0.8850\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.6409 - val_acc: 0.9025\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0348 - acc: 0.9865 - val_loss: 0.8484 - val_acc: 0.8725\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.9899 - val_acc: 0.8825\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0276 - acc: 0.9905 - val_loss: 0.6967 - val_acc: 0.8950\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0378 - acc: 0.9900 - val_loss: 0.7732 - val_acc: 0.9038\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.0444 - acc: 0.9880 - val_loss: 0.7412 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0275 - acc: 0.9880 - val_loss: 0.8248 - val_acc: 0.8925\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.8190 - val_acc: 0.9087\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0400 - acc: 0.9885 - val_loss: 0.7442 - val_acc: 0.8925\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0350 - acc: 0.9900 - val_loss: 0.8898 - val_acc: 0.8900\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.8249 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.0216 - acc: 0.9920 - val_loss: 0.8324 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.8888\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.0250 - acc: 0.9930 - val_loss: 1.0133 - val_acc: 0.8775\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 1.1741 - val_acc: 0.8662\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.8952 - val_acc: 0.8975\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.0244 - acc: 0.9920 - val_loss: 0.8963 - val_acc: 0.8850\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.8874 - val_acc: 0.8912\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.8790 - val_acc: 0.9025\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 0.0145 - acc: 0.9940 - val_loss: 0.8949 - val_acc: 0.9012\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.9398 - val_acc: 0.8950\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.0057 - acc: 0.9975 - val_loss: 1.2706 - val_acc: 0.8712\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.0280 - acc: 0.9930 - val_loss: 1.0187 - val_acc: 0.8962\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.0276 - acc: 0.9920 - val_loss: 0.9128 - val_acc: 0.8950\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.9995 - val_acc: 0.8900\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.0088 - acc: 0.9980 - val_loss: 0.9677 - val_acc: 0.8938\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 1.0332 - val_acc: 0.8862\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.9566 - val_acc: 0.8938\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', \"rb\", buffering=0))\n",
    "    train_labels = np.array(\n",
    "        [0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', \"rb\", buffering=0))\n",
    "    validation_labels = np.array(\n",
    "        [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fine-tuning the top layers of a a pre-trained network\n",
    "To further improve our previous result, we can try to \"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier. Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates. <br>In our case, this can be done in 3 steps:\n",
    "\n",
    "-instantiate the convolutional base of VGG16 and load its weights<br>\n",
    "-add our previously defined fully-connected model on top, and load its weights<br>\n",
    "-freeze the layers of the VGG16 model up to the last convolutional block<br>\n",
    "\n",
    "Training accuracy: 99.80% Testing accuracy: 93.13% with 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 88s 705ms/step - loss: 0.4013 - acc: 0.8745 - val_loss: 0.3282 - val_acc: 0.8925\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 88s 706ms/step - loss: 0.2049 - acc: 0.9195 - val_loss: 0.4266 - val_acc: 0.8975\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 88s 707ms/step - loss: 0.2043 - acc: 0.9255 - val_loss: 0.3090 - val_acc: 0.9125\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.1533 - acc: 0.9425 - val_loss: 0.2664 - val_acc: 0.9125\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1260 - acc: 0.9585 - val_loss: 0.2902 - val_acc: 0.8950\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.0979 - acc: 0.9695 - val_loss: 0.3411 - val_acc: 0.9213\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 91s 729ms/step - loss: 0.0876 - acc: 0.9690 - val_loss: 0.4312 - val_acc: 0.9213\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 89s 708ms/step - loss: 0.0563 - acc: 0.9815 - val_loss: 0.4115 - val_acc: 0.9187\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0611 - acc: 0.9780 - val_loss: 0.4580 - val_acc: 0.9175\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.0583 - acc: 0.9795 - val_loss: 0.3841 - val_acc: 0.9200\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0771 - acc: 0.9700 - val_loss: 0.3492 - val_acc: 0.9237\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0509 - acc: 0.9820 - val_loss: 0.3936 - val_acc: 0.9125\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 89s 709ms/step - loss: 0.0493 - acc: 0.9835 - val_loss: 0.3617 - val_acc: 0.9300\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.0207 - acc: 0.9925 - val_loss: 0.5259 - val_acc: 0.9075\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0522 - acc: 0.9790 - val_loss: 0.3458 - val_acc: 0.9137\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.0370 - acc: 0.9915 - val_loss: 0.3680 - val_acc: 0.9200\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 89s 709ms/step - loss: 0.0310 - acc: 0.9885 - val_loss: 0.5198 - val_acc: 0.9137\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.0498 - acc: 0.9890 - val_loss: 0.2993 - val_acc: 0.9187\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0317 - acc: 0.9880 - val_loss: 0.3681 - val_acc: 0.9225\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 89s 715ms/step - loss: 0.0285 - acc: 0.9945 - val_loss: 0.3917 - val_acc: 0.9263\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 250s 2s/step - loss: 0.0251 - acc: 0.9915 - val_loss: 0.6004 - val_acc: 0.9050\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 88s 705ms/step - loss: 0.0375 - acc: 0.9905 - val_loss: 0.4250 - val_acc: 0.9150\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0179 - acc: 0.9935 - val_loss: 0.4103 - val_acc: 0.9275\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 99s 793ms/step - loss: 0.0111 - acc: 0.9955 - val_loss: 0.4703 - val_acc: 0.9237\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 97s 774ms/step - loss: 0.0123 - acc: 0.9945 - val_loss: 0.4273 - val_acc: 0.9263\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 0.0158 - acc: 0.9955 - val_loss: 0.3799 - val_acc: 0.9225\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 0.0129 - acc: 0.9945 - val_loss: 0.4563 - val_acc: 0.9237\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 0.0055 - acc: 0.9975 - val_loss: 0.4529 - val_acc: 0.9213\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.4666 - val_acc: 0.9287\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 91s 727ms/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.4449 - val_acc: 0.9350\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.4267 - val_acc: 0.9263\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 92s 732ms/step - loss: 0.0111 - acc: 0.9955 - val_loss: 0.4875 - val_acc: 0.9213\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 91s 731ms/step - loss: 0.0048 - acc: 0.9975 - val_loss: 0.4612 - val_acc: 0.9250\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 91s 726ms/step - loss: 0.0119 - acc: 0.9985 - val_loss: 0.3951 - val_acc: 0.9313\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 92s 740ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.4427 - val_acc: 0.9325\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 91s 727ms/step - loss: 0.0056 - acc: 0.9990 - val_loss: 0.4685 - val_acc: 0.9325\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 92s 734ms/step - loss: 0.0072 - acc: 0.9960 - val_loss: 0.4214 - val_acc: 0.9313\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.5098 - val_acc: 0.9287\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.0209 - acc: 0.9950 - val_loss: 0.4729 - val_acc: 0.9263\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 90s 723ms/step - loss: 0.0143 - acc: 0.9960 - val_loss: 0.4328 - val_acc: 0.9225\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 90s 722ms/step - loss: 0.0128 - acc: 0.9975 - val_loss: 0.5373 - val_acc: 0.9250\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 91s 729ms/step - loss: 0.0124 - acc: 0.9950 - val_loss: 0.5613 - val_acc: 0.9125\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.4995 - val_acc: 0.9237\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 91s 725ms/step - loss: 0.0052 - acc: 0.9990 - val_loss: 0.5011 - val_acc: 0.9213\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.0090 - acc: 0.9955 - val_loss: 0.6125 - val_acc: 0.8912\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0180 - acc: 0.9935 - val_loss: 0.6141 - val_acc: 0.9150\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 91s 729ms/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.4294 - val_acc: 0.9213\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 0.4678 - val_acc: 0.9163\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.4050 - val_acc: 0.9300\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.4401 - val_acc: 0.9313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176c2611710>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# build the VGG16 network\n",
    "#input_tensor1 = Input(shape=(img_width,img_height,3))\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = input_shape)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "#model.add(top_model)\n",
    "model = Model(inputs= model.input, outputs= top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_fine_tune_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_23 (Sequential)   (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a new image class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Dog\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('final_fine_tune_weight.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def print_class(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img,(150,150))\n",
    "    img = np.reshape(img,[1,150,150,3])\n",
    "    classes = model.predict(img)\n",
    "    if classes[0][0]==0.0:\n",
    "        print(\"It is a Cat\")\n",
    "    elif classes[0][0]==1.0:\n",
    "        print(\"It is a Dog\")\n",
    "\n",
    "def return_class(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img,(150,150))\n",
    "    img = np.reshape(img,[1,150,150,3])\n",
    "    classes = model.predict(img)\n",
    "    return int(classes[0][0])\n",
    "    \n",
    "\n",
    "print_class(\"test.jpg\")\n",
    "print(return_class(\"test1.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix for the fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_test, predict_y):\n",
    "    C = confusion_matrix(y_test, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "   \n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "   \n",
    "    labels = [0,1]   #[0,1,2,3,4,5,6,7,8,9]\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "    \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Confusion matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAFACAYAAAB0npxWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xm8VXW9//HXh3MYZVImEVBMQQURlCsXpxJUxAHQpMSbOeGPLK9DqWFWjlkOleX16pUuBg6JQ3YlNXMWMQEBUYYQSCEQZFBBQBA5fH9/7O3pgGcCz8CC1/Px2A/2/q7vWt/POg825813TZFSQpIkKSvq1HYBkiRJW8PwIkmSMsXwIkmSMsXwIkmSMsXwIkmSMsXwIkmSMsXwIkmSMsXwIkmSMsXwIkmSMqWwtgsoS/cR3b31r1QLbhlwS22XIO20jm97fNTkeHFdbPXv2nRNqtEaS+PMiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJyhTDiyRJypTC2i5AkiTVjoPaHlTbJWwTZ14kSVKViYgGETEpIt6MiJkRcV2+/YGIeDsiZkTEPRFRN98eEXF7RMyLiLci4pCKxjC8SJKkqvQp0Del1B3oAfSPiN7AA8D+QDegIXB+vv8JQKf8axhwV0UDGF4kSVKVSTlr8h/r5l8ppfRUflkCJgHt830GAffmF00AmkdE2/LGMLxIkqQqFREFETENWAY8m1KaWGJZXeDbwNP5pnbAwhKrL8q3lcnwIkmSKi0ihkXE5BKvYVv2SSkVpZR6kJtd6RURB5ZYfCcwLqX0yuebLGWYVF4NXm0kSZIqLaU0AhhRyb4rI+IloD8wIyKuAVoB3ynRbRHQocTn9sDi8rbrzIskSaoyEdEqIprn3zcEjgVmR8T5wPHAGSmlTSVWGQuclb/qqDewKqW0pLwxnHmRJElVqS0wOiIKyE2SPJxSeiIiNgILgNciAuCxlNL1wFPAicA84BPg3IoGMLxIkqQqk1J6Czi4lPZSM0f+6qMLt2YMDxtJkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRM8SZ1AqBeQT1+P+D31C2oS2EU8uy7z3LXlLv4eZ+f07VVVzZu2siM5TO4YdwNbEwbi9fr2qor9w26jx8+/0Oee/e5L2z3gJYHcMPRN1C/oD7jF47n5r/dDEDT+k255Zhb2KPJHixevZgrnruC1RtWAzD88OEc2eFI1m9cz09f+imzP5hdMz8EqZYt/edSRl03qvjziiUrOPHcE+nzjT68/NjLvPKnV6hTUIeuvbsy6IJBX1h/1sRZPHbHY2wq2sRhJx3Gcd86DoAPlnzAqOtH8cnHn9C+c3u+fdW3KaxbyGcbPuP+X9zPwrcXskuzXTjn6nNo0bZFTe2utM2ceREAG4o2cP4T5/PNP36Tb/7xmxzR4Qi6te7GU/OeYtDDgzjt0dOoX1CfU/c/tXidOlGHS3tdyt8W/a3M7f7kyJ9w/bjrGfDQAPZsuidHdDgCgPN6nMek9yYx8KGBTHpvEkN7DAXgyA5HsmfTPRnw0ACuf+V6fnLUT6p3x6XtSJs92zB85HCGjxzOFSOuoF79enQ/qjtz3pjD9PHTGT5yOFeNuoq+p/f9wrqbijbxyG8f4YKbL+Cq0Vcx5YUpLJmfezzM43c/ztGDj+anD/yURo0b8dpTrwEw4akJNGrciKv/cDVHDz6asSPG1uj+Stuq2sJLROwfEcMj4vaI+G3+/QHVNZ6+vHUb1wFQWKeQwjqFkGD8wvHFy2csn0Gbxm2KP5/R9Qyee/c5Plz3Yanba9mwJbvU24W3lr0FwJ/n/pm+HXP/6PbZqw9j5+T+oRw7Zyx9OvbJtXfsw5/n/hmA6cum06ReE1o2bFnFeypt/96e+jYt27Vkt913Y/zj4znuP46jbr26ADTZtckX+i+YvYBW7VrRco+WFNYt5JC+hzD91emklJg7dS49vtYDgF79ezF9/HQApr86nV79ewHQ42s9mDNlDrk7tUvbt2oJLxExHBgDBDAJeD3//sGIuLI6xtSXVyfq8NDXH+LFs15kwqIJTF8+vXhZYRRycqeTeXXhqwC0btSavh378sjfHylze613ac3SNUuLPy9du5TWjVoDsFvD3VixbgUAK9atYLeGuxVv9wvr7NK66nZSyoipL0ylZ9+eACxfuJx/TP8Hv/rur/jtJb9lwewFX+i/cvlKmrdqXvy5eavmrFq+irWr1tKwcUMKCgs2awdYtXxV8ToFhQU0aNyAtavWVveuSV9adc28DAUOTSndlFK6P/+6CeiVX1aqiBgWEZMjYvIH4z6optJUlk1pE6c/djr9HujHga0PZN9d9y1edtWRVzFlyRTeeP8NAK44/Ap+M+k3bNrsqeabyz81dDOJCv5X98VVKl5H2sFs/GwjM16dQY+jc7Mlm4o28cnqT/jBnT/glAtO4ffX/r5SMyQRUfr3J/89K21Zad9baXtTXSfsbgL2IPfo65La5peVKqU0AhgB0H1Ed39j1ZLVG1bz+uLXObzD4cz7aB7fOeQ77NpwV2545obiPl1bduXmY3In3+7aYFeO2vMoijYV8eKCF4v7LF2zdLPDTG12acPyT5YD8OG6D2nZsCUr1q2gZcOWxYeelq1dlltnaYl11i6v7l2WtiuzJs6ifef2NN2tKQDNWjWj+1HdiQj2OmAvok6wZtUamjT/1+Gj5q2as3L5yuLPK5evpGnLpjRu1ph1a9ZRtLGIgsICVi5fSbOWzTZbZ9fWu1K0sYj1a9bTqGmjmt1ZaRtU18zLpcDzEfGXiBiRfz0NPA9cUk1j6kvYtcGuNKmX+4ewfkF9erfrzfyV8zl1v1M5vP3hXPn8lZv9L+3EMSdy4oO517PvPMuN42/cLLhA7nDQ2g1r6da6GwADOg3gxfm5Pi8teImBnQcCMLDzwOJ1X5r/EgM6DQCgW+turNmwpvjwkrSzmPr8VHoe07P480FHHsScN+YAsGzhMoo+K6Jxs8abrbPnfnuyfNFyPljyARs/28jUF6bS7fBuRASdDu7EtJenATDp6Ul0OyL3nTzw8AOZ9PQkAKa9PI1Oh3Ry5kWZUC0zLymlpyOiM7nDRO3ITVIuAl5PKRVVx5j6clo2asnPjv4ZdaIOdaIOz7zzDOP+OY4p509hyZol3DvoXgBemP8Cd0+9u9xtPfT1hzj9sdMBuHH8jblLpQvr8+rCV4tPAL5n2j3ceuytnLL/Kby/5n0uf+5yAF5Z+ApH7nkkTwx5gvUb13P1S1dX415L258N6zcwe8psTr/s9OK23if25g83/4FfnPMLCuoWcOaPziQiWLViFQ/e+iAX3HwBBYUFDL5kMHdecSebNm2i9wm9abt3WwAGfmcgo64fxZMjn6R9p/b0PrE3AIedeBj3/fw+rv+P62nUtBHnXH1ObeyytNViez2z3MNGUu24ZcAttV2CtNM6vu3xNTr1tS2/a98c9matT895nxdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphhdJkpQphbVdgCRJqh0H7XFQbZewTZx5kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmWJ4kSRJmVJheImIXSKiTv5954gYGBF1q780SZKkL6rMzMs4oEFEtAOeB84FRlVnUZIkKZsiokNEvBgRf4+ImRFxyRbLL4+IFBEt858jIm6PiHkR8VZEHFLRGJUJL5FS+gT4OvBfKaVTgS7bskOSJGmHtxG4LKV0ANAbuDAiukAu2ADHAf8s0f8EoFP+NQy4q6IBKhVeIuIw4FvAk/m2wsrugSRJ2nmklJaklKbm368G/g60yy++DfghkEqsMgi4N+VMAJpHRNvyxqhMeLkU+BHwp5TSzIj4CvDi1u2KJEnaEUTEsIiYXOI1rJy+HYGDgYkRMRB4L6X05hbd2gELS3xexL/CTqkqnEFJKb0MvJwvog6wIqV0cUXrSZKkHU9KaQQwoqJ+EdEY+CO5SZCNwI+BfqV1LW2Y8rZdmauN/hARTSNiF2AW8HZEXFHRepIkaeeUvyr5j8ADKaXHgH2AvYE3I2I+0B6YGhG7k5tp6VBi9fbA4vK2X5nDRl1SSh8DpwBPAXsC397K/ZAkSTuBiAhgJPD3lNKvAVJK01NKrVNKHVNKHckFlkNSSu8DY4Gz8lcd9QZWpZSWlDdGZcJL3XyCOgV4PKX0GRVM50iSpJ3WEeQmOfpGxLT868Ry+j8FvAPMA34HfK+iASpz1dDdwHzgTWBcROwFfFyJ9SRJ0k4mpTSe0s9jKdmnY4n3Cbhwa8aozAm7twO3l2haEBF9tmYQSZKkqlKp+7VExElAV6BBiebrq6UiSZKkclTmaqP/AU4HLiI3DfQNYK9qrkuSJKlUlTlh9/CU0lnARyml64DD2PySJkmSpBpTmfCyLv/nJxGxB/AZuWu1JUmSalxlznl5IiKaA7cCU8ldJv2/1VqVJElSGSpztdEN+bd/jIgngAYppVXVW5YkSVLpygwvEfH1cpaRv92vJElSjSpv5mVAOcsSYHiRJEk1rszwklI6tyYLkSRJqowyrzaKiB9ExNBS2i+KiEurtyxJkqTSlXep9HnAfaW0j8gvkyRJqnHlhZeUUtpQSuOnVPDAJUmSpOpS7k3qIqJNZdokSZJqSnnh5VbgyYj4WkQ0yb+OBv4M/LJGqpMkSdpCeVcb3RsRy8k9PfpAcpdHzwSuSSn9pYbqkyRJ2ky5d9jNhxSDiiRJ2m5U5sGMkiRJ2w3DiyRJyhTDiyRJypTyHsz4g/JWTCn9uurLkSRJKl95J+w2qbEqJEmSKqm8S6Wvq8lCtvSXYV7kJNWGdte1q+0SpJ1WuibVdgmZUO6l0gAR0QAYCnQFGnzenlLy+UaSJGXYQW0Pqu0StkllTti9D9gdOB54GWgPrK7OoiRJkspSmfCyb0rpp8DalNJo4CSgW/WWJUmSVLrKhJfP8n+ujIgDgWZAx2qrSJIkqRwVnvMCjIiIXYGfAmOBxsDV1VqVJElSGSoMLyml/82/fRn4SvWWI0mSVL7KXG1UHziN3KGi4v4ppeurryxJkqTSVeaw0ePAKmAK8Gn1liNJklS+yoSX9iml/tVeiSRJUiVU5mqjv0WEl0ZLkqTtQmVmXo4EzomId8kdNgogpZSyeVs+SZKUaZUJLydUexWSJEmVVGZ4iYimKaWP8VEAkiRpO1LezMsfgJPJXWWUyB0u+lzCe75IkqRaUGZ4SSmdnP9z75orR5IkqXyVuUndIaU0rwIWpJQ2Vn1JkiRJZavMCbt3AocAb5E7dNQNeBNoEREXpJSeqcb6JEmSNlOZ+7zMBw5OKf1bSqkn0AOYARwL3FKNtUmSJH1BZcLL/imlmZ9/SCnNIhdm3qm+siRJkkpXmcNGb0fEXcCY/OfTgTn5BzZ+Vm2VSZIklaIyMy/nAPOAS4HvA+/k2z4D+lRXYZIkSaWpcOYlpbQO+FX+taU1VV6RJElSOcq7w+7DKaVvRsR0cjel24zPNpIkSbWhvJmXS/J/nlwThUiSJFVGeXfYXRIRBcDIlNKxNViTJElSmco9YTelVAR8EhHNaqgeSZKUYRFxT0Qsi4gZW7RfFBFvR8TMiLilRPuPImJeftnxlRmjMpdKrwemR8SzwNrPG1NKF1dyPyRJ0s5jFHAHcO/nDRHRBxgEHJRS+jQiWufbuwBDgK7AHsBzEdE5P3lSpsqElyfzL0mSpHKllMZFRMctmr8L3JRS+jTfZ1m+fRAwJt/+bkTMA3oBr5U3RmXCy0PAvuSuOPpHSml9pfdAkiTtUCJiGDCsRNOIlNKIClbrDBwVETeSO6JzeUrpdaAdMKFEv0X5tnKVd6l0IfBz4DxgAbnzY9pHxO+BH6eUvLuuJEk7mXxQqSisbKkQ2BXoDRwKPBwRXyH3wOcvDFHRxso7YfdWYDdg75RSz5TSwcA+QHPgl1tZtCRJ2nktAh5LOZOATUDLfHuHEv3aA4sr2lh54eVk4P+llFZ/3pBS+pjccasTt6FwSZK0c/o/oC9ARHQG6gErgLHAkIioHxF7A52ASRVtrLxzXlJKqbQ76xZFRIVTOpIkaecTEQ8CRwMtI2IRcA1wD3BP/vLpDcDZ+YwxMyIeBmYBG4ELK7rSCMoPL7Mi4qyU0r0lGyPiTGD2tuyQJEnasaWUzihj0Zll9L8RuHFrxigvvFwIPBYR5wFTyJ1AcyjQEDh1awaRJEmqKuU9HuA94N8joi+5m8cE8JeU0vM1VZwkSdKWKrzPS0rpBeCFGqhFkiSpQuU+20iSJGl7Y3iRJEmZYniRJEmZYniRJEmZYniRJEmZYniRJEmZYniRJEmZYniRJEmZYniRJEmZUuEddiVJ0o7poD0Oqu0StokzL5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML5IkKVMML6rQo6Mf5dyTz+Wck87h0VGPfmF5Sonbf3Y73zruWwwdMJQ5M+cUL3v6T09zZr8zObPfmTz9p6eL29+e8TbnDTiPbx33LW7/2e2klGpkX6TtTf2C+kw8fyLTvjONGd+dwbVHXwtAn459mDJsCtO/O51Rg0ZREAUA7NdiP/523t9Y/+P1XHbYZWVut2PzjkwYOoE5/zmHMaeNoW6dugDUK6jHmNPGMPeiuUwYOoG9mu1VvM6VR17J3IvmMvvC2fTbp1/17bT0JRleVK5357zLk488yV2P3MXIx0fy2kuvsWj+os36TBw3kffmv8f9z9zPZTdcxm3X3gbAxys/5t477uXOh+/krkfu4t477mX1qtUA/Oba33DZ9Zdx/zP3897895g0blKN75u0Pfi06FP6ju5Lj7t70OPuHvTfpz+HtT+M0aeMZsijQ+h2VzcWrFrA2T3OBuDDdR9y8dMX88vXflnudm8+9mZum3Abne/ozEfrP2LoIUMBGHrwUD5a/xGd/qsTt024jZuPvRmAA1oewJCuQ+h6Z1f6P9CfO0+8kzrhrwhtn/ybqXIt+McCunTvQoOGDSgoLKD7od155dlXNuvz6vOv0u+UfkQEXXp0Ye3Ha/lg2Qe8Pv51eh7Rk6bNm9KkWRN6HtGTSa9M4oNlH7B2zVq6HtyViKDfKf0Y//z4WtpDqfat/WwtAHXr1KVuQV2KUhGfFn3K3A/nAvDsO89y2gGnAbD8k+VMXjyZz4o+K3ebfffuy6OzcjOlo98czSn7nQLAoP0GMfrN0QA8OutRjvnKMbn2/QcxZuYYNhRtYP7K+cz7cB692vWq+p2VqkCNh5eIOLemx9S227vz3rw1+S1WfbSK9evWM3HcRJa/v3yzPiuWrqD17q2LP7fcvSUrlq74QnurNq2K21vt3upf7bvn2qWdVZ2owxvfeYNlVyzj2XeeZdJ7k6hbpy492/YEYHCXwXRo2qHS22vRsAUr16+kKBUBsOjjRbRr2g6Adk3bsXDVQgCKUhGr1q+iRcMWtGvyr3aARasX0a5Ju6raRalK1cbMy3VlLYiIYRExOSIm3z/i/pqsSWXYa5+9GHL+EK447wqGnz+cffbbh4KCgs36lHq+SpTeHhFltks7q01pEwfffTDtf92eXnv0omurrgz54xBuO/42Jp4/kdWfrmbjpo2V3l5p36fPv3dBKctIpa+D56Jp+1RYHRuNiLfKWgS0KWu9lNIIYATAYhb7rdlOnPSNkzjpGycB8Ltf/45WbVpttrzV7q1Y9v6y4s8r3l9By9YtabV7K6ZNmlbcvnzpcnr06kGr3VttNnuz/P3ltGjdopr3Qtr+rfp0FS8teIn++/bnV6/9iq+O+ioAx33lODq36Fzp7az4ZAXNGzSnIAooSkW0b9qexasXA7lZmA7NOvDe6vcoiAKaNWjGh+s+LG7/XPsm/1pH2t5U18xLG+AsYEAprw+qaUxVk48++AiApYuX8sozr3DMycdstvzwvofzzP89Q0qJWdNmsUuTXWjRugWHHnkok8dPZvWq1axetZrJ4ydz6JGH0qJ1Cxrt0ohZ02aRUuKZ/3uGI445ojZ2Tap1LRu1pFn9ZgA0KGzAsXsfy+wVs2nVKPefhHoF9Rh+xHD+Z/L/bNV2X3z3RQZ3GQzA2d3P5vG3Hwdg7JyxnN09d/Lv4C6DeeHdF3Ltb49lSNch1CuoR8fmHenUohOT3vNEem2fqmXmBXgCaJxSmrblgoh4qZrGVDW55qJr+HjlxxQUFnDJNZfQpFkTxj44FoCBZwyk99d6M/HliZx53JnUb1if4T8fDkDT5k359ve+zQWDLwDgrAvPomnzpgB8/9rvc9OPbmLD+g30+mov/v2r/147OyfVsraN2zL6lNEU1CmgTtTh4ZkP8+TcJ7nluFs4udPJ1Ik63DX5Ll6c/yIAbXZpw+Rhk2lavymb0iYu7X0pXf67C6s3rObJ/3iS88eez5I1Sxj+3HDGDB7Dz/r+jDeWvMHIN0YCMHLqSO479T7mXjSXD9d9yJBHhwAwa/ksHp71MLO+N4uNmzZy4VMXsiltqrWfi1Se2F7vr+FhI6l2tLvOkzSl2pKuSTV6AuBfl/x1q3/XHt/2+Fo/SdFLpSVJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUqYYXiRJUpWKiO9HxMyImBERD0ZEg4jYOyImRsTciHgoIupt6/YNL5IkqcpERDvgYuDfUkoHAgXAEOBm4LaUUifgI2Doto5heJEkSVWtEGgYEYVAI2AJ0Bd4NL98NHDKtm7c8CJJkiotIoZFxOQSr2Ell6eU3gN+CfyTXGhZBUwBVqaUNua7LQK2+Smwhdu6oiRJ2vmklEYAI8paHhG7AoOAvYGVwCPACaVtaltrcOZFkiRVpWOBd1NKy1NKnwGPAYcDzfOHkQDaA4u3dQDDiyRJqkr/BHpHRKOICOAYYBbwIjA43+ds4PFtHcDwIkmSqkxKaSK5E3OnAtPJZY0RwHDgBxExD2gBjNzWMTznRZIkVamU0jXANVs0vwP0qortG14kSdpJdWvbrbZL2CYeNpIkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZlieJEkSZkSKaXarkE7oIgYllIaUdt1SDsbv3vaGTjzouoyrLYLkHZSfve0wzO8SJKkTDG8SJKkTDG8qLp4zF2qHX73tMPzhF1JkpQpzrxIkqRMMbxIkqRMMbyoSkVE/4h4OyLmRcSVtV2PtLOIiHsiYllEzKjtWqTqZnhRlYmIAuC/gROALsAZEdGldquSdhqjgP61XYRUEwwvqkq9gHkppXdSShuAMcCgWq5J2imklMYBH9Z2HVJNMLyoKrUDFpb4vCjfJklSlTG8qCpFKW1eiy9JqlKGF1WlRUCHEp/bA4trqRZJ0g7K8KKq9DrQKSL2joh6wBBgbC3XJEnawRheVGVSShuB/wT+CvwdeDilNLN2q5J2DhHxIPAasF9ELIqIobVdk1RdfDyAJEnKFGdeJElSphheJElSphheJElSphheJElSphheJElSphhepFoUEUURMS0iZkTEIxHR6Ets6+iIeCL/fmB5T/WOiOYR8b1tGOPaiLi8jGVn5fdjZkTM+rxfRIyKiMFbO5YklcXwItWudSmlHimlA4ENwAUlF0bOVn9PU0pjU0o3ldOlObDV4aUsEXECcCnQL6XUFTgEWFVV25ekkgwv0vbjFWDfiOgYEX+PiDuBqUCHiOgXEa9FxNT8DE1jgIjoHxGzI2I88PXPNxQR50TEHfn3bSLiTxHxZv51OHATsE9+1ufWfL8rIuL1iHgrIq4rsa0fR8TbEfEcsF8Ztf8IuDyltBggpbQ+pfS7LTtFxNX5MWZExIiIiHz7xfnZmrciYky+7Wv5+qZFxBsR0eRL/nwl7SAML9J2ICIKgROA6fmm/YB7U0oHA2uBnwDHppQOASYDP4iIBsDvgAHAUcDuZWz+duDllFJ3cjMiM4ErgX/kZ32uiIh+QCegF9AD6BkRX42InuQe83AwuXB0aBljHAhMqcSu3pFSOjQ/09QQODnffiVwcErpIP41+3Q5cGFKqUd+/9ZVYvuSdgKGF6l2NYyIaeQCyT+Bkfn2BSmlCfn3vYEuwKv5vmcDewH7A++mlOam3K2y7y9jjL7AXQAppaKUUmmHc/rlX2+Qm+3Zn1yYOQr4U0rpk5TSx3z5Z1X1iYiJETE9X1fXfPtbwAMRcSawMd/2KvDriLgYaJ5//IQkUVjbBUg7uXX5mYVi+SMpa0s2Ac+mlM7Yol/9Wkf8AAABhElEQVQPoKqe7xHAL1JKd28xxqWVHGMm0BN4ocwBcjNFdwL/llJaGBHXAg3yi08CvgoMBH4aEV1TSjdFxJPAicCEiDg2pTR7K/dL0g7ImRdp+zcBOCIi9gWIiEYR0RmYDewdEfvk+51RxvrPA9/Nr1sQEU2B1UDJc0j+CpxX4lyadhHRGhgHnBoRDfPnnAwoY4xfALdExO759evnZ0xK+jyorMiPMzjftw7QIaX0IvBDcicTN46IfVJK01NKN5Obmdq/vB+SpJ2HMy/Sdi6ltDwizgEejIj6+eafpJTmRMQw4MmIWAGMJ3fuyZYuAUbknzJcBHw3pfRaRLwaETOAv+TPezkAeC0/87MGODOlNDUiHgKmAQvInVRcWo1PRUQb4Ln8SbgJuGeLPisj4nfkzuuZD7yeX1QA3B8RzcjNAN2W73tDRPTJ1zwL+MvW/eQk7ah8qrQkScoUDxtJkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRMMbxIkqRM+f+tGhZoTMFaAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176c1e1c198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Precision matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAFACAYAAACfqSdVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHm9JREFUeJzt3Xu4VmWd//H3l40Ko6AOoshBIUUI0dLQZrQZz4knzNEKynEsk8GJzEMZ/ko8dM14Kv05ZWM7hzSdPM2kkWI0o6aNP01IReUoHpINKpApihSw+f7+2A/bvTf78KD72c8C3q/rei6eda973eu74NoXn32vU2QmkiRJRdat2gVIkiR1xMAiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKr3u1C2hLXBo+gleqgsUXL652CdIWqz/9oyv3937+r82Ls0trXM8ZFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHjdq12AJEmqjn133bci40bEaOA6oAa4MTOvaLF+N+BmYIdSn0mZOa29MZ1hkSRJnSYiaoDrgWOAEcC4iBjRotu3gDszcz9gLPCDjsY1sEiSpM50ILAwM1/MzNXA7cCJLfok0Lv0fXtgSUeDekpIkiR1pgHAoibLdcDHW/S5BPhVRHwF2BY4sqNBnWGRJElli4jxETGzyWd8yy6tbJYtlscBN2XmQOBY4JaIaDeTOMMiSZLKlpm1QG07XeqAQU2WB7LhKZ8zgNGl8R6LiB7ATsDStgZ1hkWSJHWmGcDQiBgSEVvTcFHt1BZ9XgGOAIiIDwM9gGXtDWpgkSRJnSYz1wITgenAXBruBpodEZdFxJhSt/OBMyNiFnAbcHpmtjxt1IynhCRJUqcqPVNlWou2yU2+zwEO3pgxnWGRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmFZ2CRJEmF55Nu1aGj9zia60ZfR023Gm588kaufPTKZut32343poyZQt9t+/LGqjc49WensvjtxRw6+FCuPfraxn7DdxrO2P8cy8/n/5wbx9zIqF1HEREs+MMCTr/ndFauWdnVhyYV2hOPPMH3//n71K+r57hPH8fnxn+u2fpZM2Zx/b9czwvzX2DyNZM5ZPQhjeteX/I63/nWd1j66lIigitqr6DfwH5c9X+uYv5z8yFh4JCBTLp8Ej237dnVhyZttOjg0f1VE5dGMQvbwnSLbiyYuICjbjmKuhV1zDhzBuP+axxzl89t7HPnKXdy7/P38pNZP+GwwYfxhY9+gdPuOa3ZODv22JGFZy9k4DUDWbV2Fb227sXbq98G4Luf/C5LVy7dIAipOhZfvLjaJQior6/ntKNP4+ofX03fXfoy4ZQJXHTNRQzec3Bjn9fqXmPlOyu5Y8odHHz4wc0Cyzl/fw6nTjiVUQePYtXKVUS3oEfPHqx8ZyXbbrctANdffj079tlxgyCk6ulP/+jK/X2k9iMb/X/trPGzurTG9So2wxIRw4ETgQFA0vBq6amZObfdDVUoBw44kIVvLOSlN18C4PbZt3Pi8BOZ+7/v/TOO6DuCc6efC8BDLz/EPWPv2WCcU0acwv3P38+qtasAGsMKQM+tepKYT6Wm5j0zj/6796f/oP4AHH7c4Tz6wKPNAku/gf0A6Nat+dn9lxe+TP3aekYdPAqg2QzK+rCSmaz+02qCqvzfI220ilzDEhHfAG4HAniChldNB3BbREyqxD5VGQN6DWDRikWNy3Ur6hjQa0CzPrNen8XJI04G4KThJ9F7m978Zc+/bNZn7Mix3Pbcbc3apoyZwmvnv8bwPsP53m+/V6EjkDZNy19fzs79dm5c7rtLX5a/vrysbetermO73tsxeeJkzvzUmdxw5Q3U19c3rr/ywis5+eCTeeXFVzjp70/q9NqlSqjURbdnAAdk5hWZeWvpcwVwYGldqyJifETMjIiZzKxQZdooERv+9tVyNuRrv/oah+x+CE+Of5JDBh9C3Yo61q5b27i+33b92GfnfZj+wvRm231x6hfpf01/5i6fy2dHfrYyByBtolo7Xd/az2Nr6tfW8+zMZ5nwjQnc8J83sKRuCb/82S8b13/j8m9w12/uYrc9duOhaQ91Ws1SJVUqsKwD+rfSvmtpXasyszYzR2XmKEZVqDJtlLoVdQzqPahxeWDvgSx5e0mzPq++8yon33ky+9fuzzcf+CYAK/68onH9Z/b+DHfPu7tZiFlvXa7jjtl3cPKHT67QEUibpr79+rL0taWNy8teX0afnfuUve2eI/ak/6D+1HSv4RNHfILn5zzfrE9NTQ2HHXsYj/zqkU6tW6qUSgWWc4AHIuL+iKgtfX4JPAB8tUL7VAXMWDyDoX2GMniHwWzVbSvG7j2WqfOnNuvTp2efxvPgF/7NhUx5akqz9eNGjtvgdNAeO+7R+P2EvU5g3vJ5FToCadM0fJ/hLH55Ma8uepU1q9fw4H0PctDhB5W17bB9hvH2W2/z5htvAvDUb59i9z13JzNZ/PuGi6ozk8ceeozdPrRbxY5B6kwVueg2M38ZEXvRcApoAA3Xr9QBMzKzvt2NVSj1Wc/EaROZfup0aqKGKU9PYc6yOVx66KXMXDKTXyz4BYcOPpTLj7icJHnk94/w5Wlfbtx+9+13Z1DvQTz88sONbUFw86dupvc2vYkIZr02i7PuO6sahycVVk33Gs6efDYXfOkC1tWv45iTj2HI0CFMuW4Kw0YO4+AjDmbeM/O4aOJFvLPiHR576DF+/L0fc9N9N1FTU8NZ3ziL8//hfJJkr7334vhPH09mcvk3Lufdle+SmewxbA/OvfTcah+qVBZva5bUjLc1S9Xjbc1t80m3kiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8AwskiSp8LpXuwBJklQd+/bft9ollM0ZFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgGFkmSVHgdBpaI2DYiupW+7xURYyJiq8qXJkmS1KCcGZZHgB4RMQB4APgCcFMli5IkSZuuiBgdEfMjYmFETGqjz2ciYk5EzI6In3Y0Zjlva47MfDcizgC+l5lXRcRTG1u8JEna/EVEDXA9cBRQB8yIiKmZOadJn6HAhcDBmfnHiNi5o3HLmWGJiPhr4PPAfaW2coKOJEna8hwILMzMFzNzNXA7cGKLPmcC12fmHwEyc2lHg5YTWM6hIQXdnZmzI+JDwEMbVbokSdosRMT4iJjZ5DO+RZcBwKImy3Wltqb2AvaKiEcj4vGIGN3RfjucKcnMh4GHS0V2A5Zn5tkdbSdJkjY/mVkL1LbTJVrbrMVyd2AocCgwEPhNRIzMzDfbGrScu4R+GhG9I2JbYA4wPyK+3tF2kiRpi1QHDGqyPBBY0kqfn2fmmsx8CZhPQ4BpUzmnhEZk5grgU8A0YDfg78utWpIkbVFmAEMjYkhEbA2MBaa26HMPcBhAROxEwymiF9sbtJzAslXpuSufopSG2HBqR5IkicxcC0wEpgNzgTtL18BeFhFjSt2mA3+IiDk0XBf79cz8Q3vjlnO3zw+Bl4FZwCMRsTuw4v0dhiRJ2txl5jQazso0bZvc5HsC55U+ZSnnott/Bf61SdPvI+KwcncgSZL0QZX1PJWIOA7YG+jRpPmyilQkSZLUQjl3Cd0AfBb4Cg23Kn0a2L3CdUmSJDUq56LbgzLzNOCPmXkp8Nc0v11JkiSposoJLKtKf74bEf2BNcCQypUkSZLUXDnXsNwbETsAVwNP0nBL840VrUqSJKmJcu4S+nbp639FxL1Aj8x8q7JlSZIkvafNwBIRf9fOOjLzZ5UpSZIkqbn2ZlhOaGddAgYWSZLUJdoMLJn5ha4sRJIkqS1t3iUUEedFxBmttH8lIs6pbFmSJEnvae+25i8Ct7TSXltaJ0mS1CXaCyyZmatbafwzDU+8lSRJ6hLtPjguInYpp02SJKmS2gssVwP3RcQhEdGr9DkU+AXwnS6pTpIkifbvEvpJRCyj4a3MI2m4lXk2cHFm3t9F9UmSJLX/pNtSMDGcSJKkqirn5YeSJElVZWCRJEmFZ2CRJEmF197LD89rb8PMvKbzy5EkSdpQexfd9uqyKiRJktrR3m3Nl3ZlIS0tvnhxNXcvbbEGXDqg2iVIW6y8OKtdQmG1e1szQET0AM4A9gZ6rG/PTN8nJEnSJmzfXfetdgllK+ei21uAfsDRwMPAQODtShYlSZLUVDmBZc/MvAhYmZk3A8cB+1S2LEmSpPeUE1jWlP58MyJGAtsDgytWkSRJUgsdXsMC1EbEjsBFwFRgO2ByRauSJElqosPAkpk3lr4+DHyosuVIkiRtqJy7hLYBTqbhNFBj/8y8rHJlSZIkvaecU0I/B94Cfgf8ubLlSJIkbaicwDIwM0dXvBJJkqQ2lHOX0P+LCG9jliRJVVPODMsngNMj4iUaTgkFkJm56TweT5IkbdLKCSzHVLwKSZKkdrQZWCKid2auwMfwS5KkKmtvhuWnwPE03B2UNJwKWi/xmSySJKmLtBlYMvP40p9Duq4cSZKkDZXz4Lj9W2l+C/h9Zq7t/JIkSZKaK+ei2x8A+wPP0HBaaB9gFtAnIiZk5q8qWJ8kSVJZz2F5GdgvM0dl5seAjwLPAUcCV1WwNkmSJKC8wDI8M2evX8jMOTQEmBcrV5YkSdJ7yjklND8i/g24vbT8WWBB6aWIaypWmSRJUkk5MyynAwuBc4BzgRdLbWuAwypVmCRJ0nodzrBk5irgu6VPS+90ekWSJEkttPek2zsz8zMR8SwND4prxncJSZKkrtLeDMtXS38e3xWFSJIktaW9J92+GhE1wL9n5pFdWJMkSVIz7V50m5n1wLsRsX0X1SNJkjZxETE6IuZHxMKImNROv1MiIiNiVEdjlnNb85+AZyPiv4GV6xsz8+yyqpYkSVuM0tmZ64GjgDpgRkRMLT3HrWm/XsDZwG/LGbecwHJf6SNJktSRA4GF6x8wGxG3AycCc1r0+zYNT8z/WjmDlhNY7gD2pOFOoRcy80/lVixJkrY4A4BFTZbrgI837RAR+wGDMvPeiCgrsLR5DUtEdI+Iq0o7uhm4FVgUEVdFxFYbW70kSdr0RcT4iJjZ5DO+ZZdWNmt8PEpEdAOuBc7fmP22N8NyNdALGJKZb5d20hv4Tunz1Xa2lSRJm6HMrAVq2+lSBwxqsjwQWNJkuRcwEvh1RAD0A6ZGxJjMnNnWoO3dJXQ8cOb6sFIqcgVwFnBsO9tJkqQt1wxgaEQMiYitgbHA1PUrM/OtzNwpMwdn5mDgcaDdsALtB5bMzNaecFtPK0++lSRJysy1wERgOjAXuDMzZ0fEZREx5v2O294poTkRcVpm/qRpY0ScCsx7vzuUJEmbt8ycBkxr0Ta5jb6HljNme4Hly8DPIuKLwO9omFU5AOgJnFTO4JIkSZ2hvUfzLwY+HhGHA3vTcNXv/Zn5QFcVJ0mSBGU8hyUzHwQe7IJaJEmSWtXuu4QkSZKKwMAiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKz8AiSZIKr8Mn3UqSpM3Tvv33rXYJZXOGRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFV73aheg4nvikSf4/j9/n/p19Rz36eP43PjPNVu/evVqLr/gchbMXkDvHXpz8bUX029gP2Y+OpPa79ayds1aum/VnQlfn8D+f70/777zLmd//uzG7Ze9toyjxhzFxG9O7OpDkwrt6D2O5rrR11HTrYYbn7yRKx+9stn6Qb0HcfOnbmaHHjtQ062GSf8zifsX3s8B/Q+g9oRaAILgkocv4Z5597BXn72445Q7Grf/0I4fYvJDk7nut9d16XFJ70dkZrVraNUSlhSzsC1MfX09px19Glf/+Gr67tKXCadM4KJrLmLwnoMb+9zzH/fw4vwXOe+y83jwvgf5zX//hov/78U8P+d5duyzIzvtshMvLXiJC864gLt+c9cG+xj/d+P58oVf5iMHfKQLj0xtGXDpgGqXIKBbdGPBxAUcdctR1K2oY8aZMxj3X+OYu3xuY58fHv9DnnrtKW6YeQMf3unDTPv8NIZcN4Se3Xuyun419VlPv+36MWvCLPp/tz/1Wd9s/MXnLebjN36cV956pRqHqFbkxRldub/pr07f6P9rj9716C6tcT1PCald856ZR//d+9N/UH+22norDj/ucB594NFmfR598FGOPuloAA45+hCefOxJMpOhI4ay0y47ATB46GBWr17N6tWrm21b93Idb/7hTfYdtW/XHJC0iThwwIEsfGMhL735EmvWreH22bdz4vATm/VJkt7b9AZg+x7bs+TtJQCsWruqMZz06N6D1n4xPWLIEbzwxguGFW0yujywRMQXunqfev+Wv76cnfvt3Ljcd5e+LH99+YZ9dm3oU9O9hu16bceKP65o1ueR6Y+w54f3ZOutt27W/sC9D3DYsYcRUZXALhXWgF4DWLRiUeNy3Yo6BvRqPvt1ya8v4dR9TmXRuYuY9rlpfOX+rzSuO3DAgTx31nM8e9azTLhvQrPZFYCxI8dy23O3VfYgpE5UjRmWS9taERHjI2JmRMy8tfbWrqxJbWjtN7OW4aLV04pNurz0/EvUfqeW8y47b4NuD017iMOPO/wD1yltbloL8Unzn7VxI8dx06ybGHTtII796bHcctItROmH74nFTzDy30ZywI8O4MJPXMg2Nds0brdVt60YM2wMd83Z8BStVFQVueg2Ip5paxWwS1vbZWYtUAtew1IUffv1ZelrSxuXl72+jD4799mwz6tL6duvL/Vr63nn7XfovUPDNPWy15YxeeJkJl05iQG7Nf/tcOG8hdTX1zNs5LDKH4i0ialbUceg3oMalwf2Hth4yme9M/Y7g9H/MRqAx+sep0f3Huz0Fzux7N1ljX3mLZ/HytUrGbnzSH736u8AOGboMTz56pMsXbkUaVNRqRmWXYDTgBNa+fyhQvtUBQzfZziLX17Mq4teZc3qNTx434McdPhBzfocdPhBTL97OgAPT3+Y/f5qPyKCd1a8w6Txk/jSeV9in4/ts8HYD977oLMrUhtmLJ7B0D5DGbzDYLbqthVj9x7L1PlTm/V55a1XOGLIEQAM32k4Pbr3YNm7yxi8w2BqogaA3bbfjWE7DePlN19u3G7cyHGeDtImp1K3Nd8LbJeZT7dcERG/rtA+VQE13Ws4e/LZXPClC1hXv45jTj6GIUOHMOW6KQwbOYyDjziY4045jn/5+r/w+aM+T+/te3PRtRcBcPetd7PklSXc8oNbuOUHtwBw9ZSr2bHPjgD8+v5fc0XtFVU7NqnI6rOeidMmMv3U6dREDVOensKcZXO49NBLmblkJr9Y8AvO/9X5/OiEH3HuX51Lkpx+z+kAfGK3TzDp4EmsWbeGdbmOf7rvn/jDqobfFXt278lRHzqKf7z3H6t4dNLG87ZmSc14W7NUPd7W3DZva5YkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSYVnYJEkSZ0qIkZHxPyIWBgRk1pZf15EzImIZyLigYjYvaMxDSySJKnTREQNcD1wDDACGBcRI1p0ewoYlZn7Av8JXNXRuAYWSZLUmQ4EFmbmi5m5GrgdOLFph8x8KDPfLS0+DgzsaFADiyRJKltEjI+ImU0+41t0GQAsarJcV2pryxnA/R3tt/vGlypJkrZUmVkL1LbTJVrbrNWOEacCo4BDOtqvgUWSJHWmOmBQk+WBwJKWnSLiSOCbwCGZ+eeOBvWUkCRJ6kwzgKERMSQitgbGAlObdoiI/YAfAmMyc2k5gxpYJElSp8nMtcBEYDowF7gzM2dHxGURMabU7WpgO+CuiHg6Iqa2MVwjTwlJkrSF2mfXfSoybmZOA6a1aJvc5PuRGzumMyySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwDCySJKnwIjOrXYM2QxExPjNrq12HtKXxZ0+bK2dYVCnjq12AtIXyZ0+bJQOLJEkqPAOLJEkqPAOLKsVz6FJ1+LOnzZIX3UqSpMJzhkWSJBWegUWSJBWegUWdKiJGR8T8iFgYEZOqXY+0pYiIKRGxNCKeq3YtUiUYWNRpIqIGuB44BhgBjIuIEdWtStpi3ASMrnYRUqUYWNSZDgQWZuaLmbkauB04sco1SVuEzHwEeKPadUiVYmBRZxoALGqyXFdqkyTpAzGwqDNFK23eNy9J+sAMLOpMdcCgJssDgSVVqkWStBkxsKgzzQCGRsSQiNgaGAtMrXJNkqTNgIFFnSYz1wITgenAXODOzJxd3aqkLUNE3AY8BgyLiLqIOKPaNUmdyUfzS5KkwnOGRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRZIkFZ6BRaqiiKiPiKcj4rmIuCsi/uIDjHVoRNxb+j6mvbdlR8QOEfFP72Mfl0TE19pYd1rpOGZHxJz1/SLipog4ZWP3JUlNGVik6lqVmR/NzJHAamBC05XRYKN/TjNzamZe0U6XHYCNDixtiYhjgHOAT2bm3sD+wFudNb4kGVik4vgNsGdEDI6IuRHxA+BJYFBEfDIiHouIJ0szMdsBRMToiJgXEf8L/N36gSLi9Ij4fun7LhFxd0TMKn0OAq4A9ijN7lxd6vf1iJgREc9ExKVNxvpmRMyPiP8BhrVR+4XA1zJzCUBm/ikzf9SyU0RMLu3juYiojYgotZ9dmpV5JiJuL7UdUqrv6Yh4KiJ6fcC/X0mbMAOLVAAR0R04Bni21DQM+Elm7gesBL4FHJmZ+wMzgfMiogfwI+AE4G+Afm0M/6/Aw5n5ERpmPmYDk4AXSrM7X4+ITwJDgQOBjwIfi4i/jYiP0fCKhf1oCEQHtLGPkcDvyjjU72fmAaUZpZ7A8aX2ScB+mbkv780yfQ34cmZ+tHR8q8oYX9JmysAiVVfPiHiahhDyCvDvpfbfZ+bjpe9/BYwAHi31/Qdgd2A48FJmPp8Nj6y+tY19HA78G0Bm1mdma6dqPln6PEXDrM5wGgLM3wB3Z+a7mbmCD/5uqMMi4rcR8Wyprr1L7c8A/xERpwJrS22PAtdExNnADqVXP0jaQnWvdgHSFm5VaQahUeksycqmTcB/Z+a4Fv0+CnTWuzUCuDwzf9hiH+eUuY/ZwMeAB9vcQcOM0A+AUZm5KCIuAXqUVh8H/C0wBrgoIvbOzCsi4j7gWODxiDgyM+dt5HFJ2kw4wyIV3+PAwRGxJ0BE/EVE7AXMA4ZExB6lfuPa2P4B4KzStjUR0Rt4G2h6Tch04ItNro0ZEBE7A48AJ0VEz9I1JCe0sY/Lgasiol9p+21KMyNNrQ8ny0v7OaXUtxswKDMfAi6g4YLg7SJij8x8NjOvpGEGanh7f0mSNm/OsEgFl5nLIuJ04LaI2KbU/K3MXBAR44H7ImI58L80XEvS0leB2tLbe+uBszLzsYh4NCKeA+4vXcfyYeCx0gzPO8CpmflkRNwBPA38noYLg1urcVpE7AL8T+lC2gSmtOjzZkT8iIbrdF4GZpRW1QC3RsT2NMz0XFvq++2IOKxU8xzg/o37m5O0OfFtzZIkqfA8JSRJkgrPwCJJkgrPwCJJkgrPwCJJkgrPwCJJkgrPwCJJkgrPwCJJkgrv/wPFgP306gxmjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176c06be978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of columns in precision matrix [1. 1.]\n",
      "-------------------------------------------------- Recall matrix --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x176c51af898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of rows in precision matrix [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "nb_validation_samples = 800\n",
    "validation_actual = np.array(\n",
    "        [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
    "validation_predicted = []\n",
    "j=k=0\n",
    "for i in range(int(nb_validation_samples / 2)):\n",
    "    j=1000+i\n",
    "    validation_predicted.append(return_class(\"data/validation/cats/cat.%s.jpg\" % j))\n",
    "\n",
    "for i in range(int(nb_validation_samples / 2)):\n",
    "    k=1000+i\n",
    "    validation_predicted.append(return_class(\"data/validation/dogs/dog.%s.jpg\" % k))\n",
    "validation_predicted = np.array(validation_predicted)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(validation_actual, validation_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
